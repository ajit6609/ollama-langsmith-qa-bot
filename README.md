# ğŸ¤– Ollama + LangSmith Q&A Bot

An AI-powered chatbot built with **Ollama's Gemma:2B model**, integrated with **LangSmith** for advanced conversation tracking, and deployed via **Streamlit** for an interactive UI.  
Perfect for answering questions, experimenting with local LLMs, and tracking performance in real time.

---

## âœ¨ Features

- ğŸ” **Local LLM** â€” Uses `gemma:2b` from Ollama (fast & private inference)
- ğŸ“Š **LangSmith Tracing** â€” Every conversation is tracked and visualized
- ğŸ¨ **Streamlit Interface** â€” Clean, minimal, and interactive chat UI
- ğŸ”’ **.env for Secrets** â€” Keeps API keys safe & out of GitHub
- ğŸ›  **Customizable Prompt Pipeline** â€” Built with LangChain for easy tweaking

---

## ğŸ“¸ Demo Screenshots

<img width="1211" height="601" alt="image" src="https://github.com/user-attachments/assets/a9f3f3b7-c826-4007-afdf-9128e2a69c3f" />


---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

### 2ï¸âƒ£ Setup .env
Create a .env file in the project root:
LANGCHAIN_API_KEY=ls__your_langsmith_api_key
LANGCHAIN_PROJECT=ollama-langsmith-bot

### 3ï¸âƒ£ Run Ollama
Make sure Ollama is installed and the gemma:2b model is pulled:
ollama run gemma:2b

### 4ï¸âƒ£ Start Streamlit App
streamlit run app.py

# Created with â¤ï¸ by Ajit
